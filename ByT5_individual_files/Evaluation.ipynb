{"cells":[{"cell_type":"markdown","metadata":{"id":"_kbkVzu9QNnN"},"source":["# INSTALLS AND IMPORTS"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3216,"status":"ok","timestamp":1638801784214,"user":{"displayName":"Emil helgren","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16470713661505960408"},"user_tz":-60},"id":"cMbv7LB0n7je","outputId":"52f12127-e458-401d-bc72-4089eb83d81a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.7/dist-packages (0.12.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein) (57.4.0)\n"]}],"source":["### INSTALL DEPENDENCIES\n","!pip install python-Levenshtein\n","!pip uninstall nltk\n","!pip install nltk==3.6.2"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"yeUjTW4lm06J"},"outputs":[],"source":["### IMPORT LIBRARIES\n","import pandas as pd\n","import numpy as np\n","import sys\n","import os\n","import Levenshtein as Lev"]},{"cell_type":"markdown","metadata":{"id":"P7Pk_j9bQL8N"},"source":["# FUNKTIONER"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"hA-n0YQOrd0B"},"outputs":[],"source":["def wer(s1, s2):\n","    \"\"\"\n","    Computes the Word Error Rate, defined as the edit distance between the\n","    two provided sentences after tokenizing to words.\n","    Arguments:\n","        s1 (string): space-separated sentence\n","        s2 (string): space-separated sentence\n","    \"\"\"\n","\n","    # build mapping of words to integers\n","    b = set(s1.split() + s2.split())\n","    word2char = dict(zip(b, range(len(b))))\n","\n","    # map the words to a char array (Levenshtein packages only accepts\n","    # strings)\n","    w1 = [chr(word2char[w]) for w in s1.split()]\n","    w2 = [chr(word2char[w]) for w in s2.split()]\n","\n","    return Lev.distance(''.join(w1), ''.join(w2))\n","\n","def wer_normalized(s1, s2):\n","  return wer(s1.lower(),s2.lower()) / len(s2.split(\" \"))\n","def calculate_wer(df):\n","  return wer_normalized(df['corrected'],df['reference_text'])"]},{"cell_type":"markdown","metadata":{"id":"gxKNUAU6grWB"},"source":["# ByT5 evaluation\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"QV4WOaJUhvmo"},"outputs":[],"source":["df = pd.read_pickle('/Users/jenspt/Desktop/git/DL-ByT5/data/ByT5_lr_1e4.pkl')"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"QXcp0E_bh11o"},"outputs":[],"source":["df['corrected_wer'] = df.apply(calculate_wer,axis=1)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":352,"status":"ok","timestamp":1638715565355,"user":{"displayName":"Jens PT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVgxxg3JYFI3crIX4EtRvr0znKFyTycHMlDg9q=s64","userId":"06468387824280869935"},"user_tz":-60},"id":"dCZLLcI5z9Sn","outputId":"1d505a1b-86af-4995-905d-2588514b9b43"},"outputs":[{"name":"stdout","output_type":"stream","text":["MLN WER:  6.465655469246048\n"]}],"source":["print(\"MLN WER: \", df['corrected_wer'].mean()*100)\n"]},{"cell_type":"markdown","metadata":{"id":"xr47s4vB_PfT"},"source":["# BLEU & GLEU"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"7KJbNDPj_RxO"},"outputs":[],"source":["from nltk.translate.bleu_score import sentence_bleu\n","from nltk.translate.gleu_score import sentence_gleu"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":287,"status":"ok","timestamp":1638803594063,"user":{"displayName":"Emil helgren","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16470713661505960408"},"user_tz":-60},"id":"NZuzXfjH_VPy"},"outputs":[],"source":["def calculate_bleu_baseline_normalized(df):\n","  total_bleu = 0\n","  for i in range(len(df)):\n","    ref = [df['reference_text'].iloc[i].split(\" \")]\n","    hyp = df['transcription'].iloc[i].split(\" \")\n","    sentence_bleu_score = sentence_bleu(ref, hyp)\n","    total_bleu += sentence_bleu_score\n","  return total_bleu / len(df)\n","\n","def calculate_gleu_baseline_normalized(df):\n","  total_gleu = 0\n","  for i in range(len(df)):\n","    ref = [df['reference_text'].iloc[i].split(\" \")]\n","    hyp = df['transcription'].iloc[i].split(\" \")\n","    sentence_gleu_score = sentence_gleu(ref, hyp)\n","    total_gleu += sentence_gleu_score\n","  return total_gleu / len(df)\n","\n","def calculate_bleu_normalized(df):\n","  total_bleu = 0\n","  for i in range(len(df)):\n","    ref = [df['reference_text'].iloc[i].split(\" \")]\n","    hyp = df['corrected'].iloc[i].split(\" \")\n","    sentence_bleu_score = sentence_bleu(ref, hyp)\n","    total_bleu += sentence_bleu_score\n","  return total_bleu / len(df)\n","\n","def calculate_gleu_normalized(df):\n","  total_gleu = 0\n","  for i in range(len(df)):\n","    ref = [df['reference_text'].iloc[i].split(\" \")]\n","    hyp = df['corrected'].iloc[i].split(\" \")\n","    sentence_gleu_score = sentence_gleu(ref, hyp)\n","    total_gleu += sentence_gleu_score\n","  return total_gleu / len(df)\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3533,"status":"ok","timestamp":1638802577563,"user":{"displayName":"Emil helgren","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16470713661505960408"},"user_tz":-60},"id":"etxyYE_o_n7s","outputId":"987bd61c-568d-49a5-b07c-e4dc7c2d48ed"},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/homebrew/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/opt/homebrew/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/opt/homebrew/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]},{"name":"stdout","output_type":"stream","text":["\n","Normalized bleu:\n","0.8320419867936647\n","\n","Normalized gleu:\n","0.8952613840069592\n"]}],"source":["\n","#corpus_bleu_score = calculate_bleu_corpus(df)\n","norm_bleu_score = calculate_bleu_normalized(df)\n","#calculated_gleu = calculate_gleu(df) #RuntimeError: generator raised StopIteration\n","\n","\n","#print(\"\\nCorpus bleu:\")\n","#print(corpus_bleu_score)\n","print(\"\\nNormalized bleu:\")\n","print(norm_bleu_score)\n","#print(calculated_gleu)\n","\n","#corpus_bleu_score = calculate_bleu_corpus(df)\n","norm_gleu_score = calculate_gleu_normalized(df)\n","#calculated_gleu = calculate_gleu(df) #RuntimeError: generator raised StopIteration\n","\n","\n","#print(\"\\nCorpus bleu:\")\n","#print(corpus_bleu_score)\n","print(\"\\nNormalized gleu:\")\n","print(norm_gleu_score)\n","#print(calculated_gleu)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cGMZ8CdjDthB"},"outputs":[],"source":["## GLEU SCORES\n","# Baseline (transcription)= 0.8534873003494211\n","# ByT5_lr_1e4             = 0.8952613840069592\n","# ByT5_ws3000             = 0.8873560947109903\n","# ByT5                    = 0.887649053358017\n","# ByT5_extra_layer        = 0.0\n","# MultiLexNorm_raw_data   = 0.7097791013001765\n","# MultiLexNorm_base       = 0.6818061444602583\n","# MultiLexNorm_Fine_tuned = 0.1129387766622926\n","\n","\n","## BLEU SCORES (normalized)\n","# Baseline (transcription)= 0.7871290040412282\n","# ByT5                    = 0.8233903148477896\n","# ByT5_lr_1e4             = 0.8320419867936647\n","# ByT5_ws3000             = 0.8231682536463248\n","# ByT5_extra_layer        = 0.0\n","# MultiLexNorm_raw_data   = 0.6473379750494206\n","# MultiLexNorm_base       = 0.6190157431613983\n","# MultiLexNorm_fine_tuned = 0.006133337391333845\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Evaluation.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.9"}},"nbformat":4,"nbformat_minor":0}
